<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>urn:2021-12-31T01:06:28.636Z</id>
    <title>osmos::feed</title>
    <updated>2021-12-31T01:06:28.636Z</updated>
    <generator>osmosfeed 1.11.3</generator>
    <link rel="alternate" href="index.html"/>
    <entry>
        <title type="html"><![CDATA[彻底搞懂 Kubernetes 中的 Events]]></title>
        <id>https://moelove.info/2021/12/28/%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82-Kubernetes-%E4%B8%AD%E7%9A%84-Events/</id>
        <link href="https://moelove.info/2021/12/28/%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82-Kubernetes-%E4%B8%AD%E7%9A%84-Events/"/>
        <updated>2021-12-28T14:12:37.000Z</updated>
        <summary type="html"><![CDATA[大家好，我是张晋涛。
之前我写了一篇《更优雅的 Kubernetes 集群事件度量方案》，利用 Jaeger 利用 tracing 的方式来采集 Kubernetes 集群中的 events 并进行展示。最终效果如下：

写那篇文章的时候，立了个 flag 要详细介绍下其中的原理，鸽了很久，现在年底了，也该发出来了。
Eents 概览
我们先来做个简单的示例，来看看 Kubernetes 集群中的 events 是什么。
创建一个新的名叫 moelove 的 namespace ，然后在其中创建一个叫做 redis 的 deployment。接下来查看这个 namespace 中的所有 events。
(MoeLove) ➜ kubectl create ns moelove
namespace/moelove created
(MoeLove) ➜ kubectl -n moelove create deployment redis --image=ghcr.io/moelove/redis:alpine
deployment.apps/redis created
(MoeLove) ➜ kubectl -n moelove get deploy
NAME READY UP-TO-DATE AVAILABLE AGE
redis 1/1 1 1 11s
(MoeLove) ➜ kubectl -n moelove get events
LAST SEEN TYPE REASON OBJECT MESSAGE
21s Normal Scheduled pod/redis-687967dbc5-27vmr Successfully assigned moelove/redis-687967dbc5-27vmr to kind-worker3
21s Normal Pullin…]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git 仓库瘦身与 LFS 大文件存储]]></title>
        <id>https://yeshan333.github.io/2021/12/26/git-lfs-and-thin-repo/</id>
        <link href="https://yeshan333.github.io/2021/12/26/git-lfs-and-thin-repo/"/>
        <updated>2021-12-26T16:26:23.000Z</updated>
        <summary type="html"><![CDATA[熟悉 Git 的小伙伴应该都知道随着 Git 仓库维护的时间越来越久，追踪的文件越来越多，git 存储的 objects 数量会极其庞大，每次从远程仓库 git clone 的时候都会墨迹很久。如果我们不小心 git add 了一个体积很大的文件，且 git push 到了远程仓库，那么我们 git clone 的时候也会很慢。
看一下 GitHub 上的 microsoft/vscode 仓库，都有 九万多个 commit 了，可想而知 objects 的数量应该很恐怖，尝试 clone 一下（一百多万个 objects）：]]></summary>
        <author>
            <name>ShanSan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[K8S 生态周报| Helm 新版本发布，解决了内存泄漏的问题]]></title>
        <id>https://moelove.info/2021/12/26/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-%E6%96%B0%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83%E8%A7%A3%E5%86%B3%E4%BA%86%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E9%97%AE%E9%A2%98/</id>
        <link href="https://moelove.info/2021/12/26/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-%E6%96%B0%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83%E8%A7%A3%E5%86%B3%E4%BA%86%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E9%97%AE%E9%A2%98/"/>
        <updated>2021-12-26T15:57:25.000Z</updated>
        <summary type="html"><![CDATA[「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Trivy v0.22.0 正式发布
Trivy 是一款轻量级的漏洞扫描工具，支持包括容器镜像，文件系统，IaC 配置文件等。在我之前的 『K8s生态周报』文章中已经介绍过多次，此处就不再展开了。我们一起来看看这个版本中有哪些值得关注的变更。
新增了一个 --offline-scan 的选项，在对 pom.xml 和 JAR 文件进行扫描的时候，可以通过同时指定 --skip-update 和 --offline-scan 参数来避免 Trivy 去发起更新漏洞库的请求。在离线环境或者网络不好的场景下会比较有用；
优化了内存的使用，在之前版本的逻辑中，如果对于大文件也会直接进行读取，有可能会造成 OOM 。本次修正了该问题，加入了一定的缓存。如果你正在使用 Trivy ，我建议你进行更新；
再对 rpm 包扫描的时候， 支持了 NDB 格式 ， 对此格式感兴趣的小伙伴可以去看看 rpm 项目的发版说明。
你可以直接去它的 Release 页面下载最新的二进制，也可以直接使用其容器镜像。
(MoeLove) ➜ docker pull aquasec/trivy:0.22.0


对于此版本的其他变更，可参考其 ReleaseNote
Helm v3.7.2 发布
Helm 最新一个大版本是 v3.7.0，但如果你去关注这个项目实际的变更，你会发现即使是大版本更新，也没有携带特别值得有价值的内容。反倒是这个小版本中还带来了一些值得注意的内容：
修复了一个 Helm upgrade 时，内存泄漏的问题，感兴趣的小伙伴可以去围观下 https://github.com/helm/helm/issues/10439
至于之前版本中的变更，感兴趣的小伙伴可以自行去…]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[sqlite3.36版本 btree实现（三）- journal文件备份机制]]></title>
        <id>https://www.codedump.info/post/20211222-sqlite-btree-3-journal/</id>
        <link href="https://www.codedump.info/post/20211222-sqlite-btree-3-journal/"/>
        <updated>2021-12-22T11:15:31.000Z</updated>
        <summary type="html"><![CDATA[概述 在上一节中（sqlite3.36版本 btree实现（二）- 并发控制框架），已经讲解了sqlite中的并发控制机制，里面会涉及到一个“备份]]></summary>
        <author>
            <name>codedump的网络日志</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[我做系统架构的一些原则]]></title>
        <id>https://coolshell.cn/?p=21672</id>
        <link href="https://coolshell.cn/articles/21672.html"/>
        <updated>2021-12-21T07:46:41.000Z</updated>
        <summary type="html"><![CDATA[工作 20 多年了，这 20 来年看到了很多公司系统架构，也看到了很多问题，在跟这些公司进行交流和讨论的时候，包括进行实施和方案比较的时候，都有很多各种方案的比...
 Read More  Read More
我做系统架构的一些原则 first appeared on 酷 壳 - CoolShell.]]></summary>
        <author>
            <name>陈皓</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[倍受关注的 Cilium Service Mesh 到底怎么玩？ - 上手实践]]></title>
        <id>https://moelove.info/2021/12/21/%E5%80%8D%E5%8F%97%E5%85%B3%E6%B3%A8%E7%9A%84-Cilium-Service-Mesh-%E5%88%B0%E5%BA%95%E6%80%8E%E4%B9%88%E7%8E%A9-%E4%B8%8A%E6%89%8B%E5%AE%9E%E8%B7%B5/</id>
        <link href="https://moelove.info/2021/12/21/%E5%80%8D%E5%8F%97%E5%85%B3%E6%B3%A8%E7%9A%84-Cilium-Service-Mesh-%E5%88%B0%E5%BA%95%E6%80%8E%E4%B9%88%E7%8E%A9-%E4%B8%8A%E6%89%8B%E5%AE%9E%E8%B7%B5/"/>
        <updated>2021-12-20T18:30:17.000Z</updated>
        <summary type="html"><![CDATA[大家好，我是张晋涛。
Cilium 是一个基于 eBPF 技术，用于为容器工作负载间提供安全且具备可观测性的网络连接的开源软件。
如果你对 Cilium 还不太了解，可以参考我之前的两篇文章：
K8S生态周报| Google 选择 Cilium 作为 GKE 下一代数据面
Cilium 上手实践
最近 Cilium v1.11.0 正式发布了，增加 Open Telemetry 的支持以及其他一些增强特性。同时，也宣布了 Cilium Service Mesh 的计划。当前 Cilium Service Mesh 正处于测试阶段，预期在 2022 年会合并到 Cilium v1.12 版本中。
Cilium Service Mesh 也带来了一个全新的模式。
Cilium 直接通过 eBPF 技术实现的 Service Mesh 相比我们常规的 Istio/Linkerd 等方案，最显著的特点就是将 Sidecar proxy 模型替换成了 Kernel 模型， 如下图：

不再需要每个应用程序旁边都放置一个 Sidecar 了，直接在每台 Node 上提供支持。

我在几个月前就已经知道了这个消息并且进行了一些讨论，最近随着 isovalent 的一篇文章 How eBPF will solve Service Mesh - Goodbye Sidecars ，Cilium Service Mesh 也成为了大家关注的焦点。
本篇我带你实际体验下 Cilium Service Mesh。
安装部署
这里我使用 KIND 作为测试环境，我的内核版本是 5.15.8 。
准备 KIND 集群
关于 KIND 命令行工具的安装这里就不再赘述了，感兴趣的小伙伴可以参考我之前的文章 《使用KIND搭建自己的本地 Kubernetes 测试环境》。
以下是我创建集群使用的配置文件：
…]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GitOps 应用实践系列 - Flux CD 及其核心组件]]></title>
        <id>https://moelove.info/2021/12/18/GitOps-%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%E7%B3%BB%E5%88%97-Flux-CD-%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/</id>
        <link href="https://moelove.info/2021/12/18/GitOps-%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%E7%B3%BB%E5%88%97-Flux-CD-%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"/>
        <updated>2021-12-18T12:56:29.000Z</updated>
        <summary type="html"><![CDATA[大家好，我是张晋涛。
经过前面三篇文章，不仅为大家介绍了什么是 GitOps 也介绍了如何利用 Argo CD 来实施 GitOps。本篇我来为你介绍另一个可用于实施 GitOps 的工具：Flux CD 。
Flux CD

Flux 是一组可支持实现 GitOps 的工具，用于使 Kubernetes 集群与配置源（如 Git 仓库）保持同步，并在有代码更新后自动同步配置，面向 Kubernetes 的持续渐进式交付解决方案。

Flux CD 的发展历史
2016 年 10 月 28 日，Flux single-user service 版本发布。
它奠定了 flux 的两个基调：
集中式运行的服务
以守护进程的方式，在自动模式下运行在 k8s 集群中
2016 年 12 月 15 日，发布《使用 Weave Flux 持续交付》，构建了将 CI 与持续部署 (CD) 联系起来的 Flux。
​ 
2017 年 8 月 22 日，v1.0.0 版本正式发布。
自 v1.0.0 开始，Flux 致力于将集群与存储在 Git 中的配置同步，并在新版本准备好部署时自动升级镜像。（提出了：Configuration as code）
​ 
2018 年 5 月 1 日，发布的 alpha 版本中，集成了 Helm Operator 。这是 Flux Helm Operator 的第一个 alpha 标签的版本。
2019 年 8 月 15 日，Flux 宣布加入 CNCF Sandbox。随着各开发者及企业开始落地 GitOps ，Flux 的用户数量不断增长。 彼时已超过 2500 个 GitHub star，也在不断地集成：Helm Operator 、 Kustomize 、 Weave Flagger 、 OpenFaaS 、 Fluxcloud 、 Flux Web…]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[sqlite3.36版本 btree实现（二）- 并发控制框架]]></title>
        <id>https://www.codedump.info/post/20211218-sqlite-btree-2-concurrency-control/</id>
        <link href="https://www.codedump.info/post/20211218-sqlite-btree-2-concurrency-control/"/>
        <updated>2021-12-18T07:25:05.000Z</updated>
        <summary type="html"><![CDATA[概述 按照之前起步阶段对sqlite btree整体架构的分析，“页面管理模块”分为以下几个子模块： 页面缓存管理。 崩溃恢复，又分为以下两种实现：]]></summary>
        <author>
            <name>codedump的网络日志</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[sqlite3.36版本 btree实现（一）- 管理页面缓存]]></title>
        <id>https://www.codedump.info/post/20211217-sqlite-btree-1-pagecache/</id>
        <link href="https://www.codedump.info/post/20211217-sqlite-btree-1-pagecache/"/>
        <updated>2021-12-17T06:22:06.000Z</updated>
        <summary type="html"><![CDATA[概述 页面管理模块中，很重要的一个功能是缓存页面的内容在内存中： 读页面：如果页面已经在内存，就不需要到文件中读出页面内容。 写页面：如果页面已经]]></summary>
        <author>
            <name>codedump的网络日志</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[sqlite3.36版本 btree实现（零）- 起步及概述]]></title>
        <id>https://www.codedump.info/post/20211217-sqlite-btree-0/</id>
        <link href="https://www.codedump.info/post/20211217-sqlite-btree-0/"/>
        <updated>2021-12-17T02:19:05.000Z</updated>
        <summary type="html"><![CDATA[起步 在去年大体把btree以及b+tree算法流程研究了之后，我写了两篇博客： B树、B+树索引算法原理（上） - codedump的网络日志 B树]]></summary>
        <author>
            <name>codedump的网络日志</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Grafana k6 的上手实践]]></title>
        <id>https://moelove.info/2021/12/17/Grafana-k6-%E7%9A%84%E4%B8%8A%E6%89%8B%E5%AE%9E%E8%B7%B5/</id>
        <link href="https://moelove.info/2021/12/17/Grafana-k6-%E7%9A%84%E4%B8%8A%E6%89%8B%E5%AE%9E%E8%B7%B5/"/>
        <updated>2021-12-16T19:50:29.000Z</updated>
        <summary type="html"><![CDATA[大家好，我是张晋涛。
本篇我将为你介绍一个工具 - k6 ，它和 K8s 并没有什么直接的关系，它是一款开源的性能压测工具。
k6 背后的故事
2016 年 8 月，k6 在 GitHub 上发布了第一个版本，至此，一个出色的开源负载压测工具进入了人们的视野。
2021 年的 6 月，对于 Grafana 和 k6 来讲是个大日子，Grafana Labs 收购了 k6 。
而事实上， Grafana 与 k6 的缘分还要追溯到更早的 2 年前。
2019 年，在进行 Grafana 6.0 的短期令牌刷新行为的压测时，Grafana Labs 进行了一系列的技术选型。
由于 Grafana Labs 的大部分后端软件是使用 Go 来实现的，恰巧 k6 满足 OSS 和 Go 需求，并且负载测试是使用 JS 编写（Grafana 前端框架及 UI 都在使用）。这使得 k6 自 Grafana 6.0 版本开始，不断地为 Grafana 开发者及测试者完成追踪 bug 的使命。

图 1 ，k6 加入 Grafana Labs
多样的压测工具
一个称心应手的自动化负载压测工具会极大的提升程序开发人员的代码质量及效率。
下图中是一些比较常见的用于负载压测的工具，我们可以在 GitHub 上看到，目前，更新比较频繁、活跃的项目主要有：Gatling, Jmeter 和 k6 。

图 2 ，压测工具们
如何从中选择，简单的讲就是工具效率的比拼。主要从以下两个方面来考量：
工具性能
工具使用体验
下图对以上工具进行了一些简单的对比。

这里我主要对比下其中较为活跃的 3 个项目。
JMeter - 熟悉 Java 的小伙伴可能比较了解这个工具。由于存在时间久，JMeter 的功能是这之中最全面的，并且集成、附加组件做的较好。基于它构建的 SaaS 服务 Blazemeter，相信大…]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[搞懂容器技术的基石： namespace （下）]]></title>
        <id>https://moelove.info/2021/12/13/%E6%90%9E%E6%87%82%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%9F%BA%E7%9F%B3-namespace-%E4%B8%8B/</id>
        <link href="https://moelove.info/2021/12/13/%E6%90%9E%E6%87%82%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%9F%BA%E7%9F%B3-namespace-%E4%B8%8B/"/>
        <updated>2021-12-12T19:50:29.000Z</updated>
        <summary type="html"><![CDATA[大家好，我是张晋涛。
目前我们所提到的容器技术、虚拟化技术（不论何种抽象层次下的虚拟化技术）都能做到资源层面上的隔离和限制。
对于容器技术而言，它实现资源层面上的限制和隔离，依赖于 Linux 内核所提供的 cgroup 和 namespace 技术。
我们先对这两项技术的作用做个概括：
cgroup 的主要作用：管理资源的分配、限制；
namespace 的主要作用：封装抽象，限制，隔离，使命名空间内的进程看起来拥有他们自己的全局资源；
这是一个系列文章，对此系列感兴趣的小伙伴可以查看：
彻底搞懂容器技术的基石：cgroup
彻底搞懂容器技术的基石：namespace（上）
本篇我们将继续聊 namespace。
Namespace 类型
我们先来总览一下 namespace 的类型，上篇中已经为大家介绍过 Cgroup , IPC, Network 和 Mount 等 4 种类型的 namespace。我们继续聊剩余的部分。
namespace名称
使用的标识 - Flag
控制内容




Cgroup
CLONE_NEWCGROUP
Cgroup root directory cgroup 根目录


IPC
CLONE_NEWIPC
System V IPC, POSIX message queues信号量，消息队列


Network
CLONE_NEWNET
Network devices, stacks, ports, etc.网络设备，协议栈，端口等等


Mount
CLONE_NEWNS
Mount points挂载点


PID
CLONE_NEWPID
Process IDs进程号


Time
CLONE_NEWTIME
Boot and monotonic clocks启动和单调时钟


User
CLONE_NEWUSER
User and …]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[搞懂容器技术的基石： namespace （上）]]></title>
        <id>https://moelove.info/2021/12/10/%E6%90%9E%E6%87%82%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%9F%BA%E7%9F%B3-namespace-%E4%B8%8A/</id>
        <link href="https://moelove.info/2021/12/10/%E6%90%9E%E6%87%82%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9A%84%E5%9F%BA%E7%9F%B3-namespace-%E4%B8%8A/"/>
        <updated>2021-12-09T19:50:29.000Z</updated>
        <summary type="html"><![CDATA[大家好，我是张晋涛。
目前我们所提到的容器技术、虚拟化技术（不论何种抽象层次下的虚拟化技术）都能做到资源层面上的隔离和限制。
对于容器技术而言，它实现资源层面上的限制和隔离，依赖于 Linux 内核所提供的 cgroup 和 namespace 技术。
我们先对这两项技术的作用做个概括：
cgroup 的主要作用：管理资源的分配、限制；
namespace 的主要作用：封装抽象，限制，隔离，使命名空间内的进程看起来拥有他们自己的全局资源；
在上一篇文章中，我们重点聊了 cgroup 。本篇，我们重点来聊 namespace 。
Namespace 是什么？
我们引用 wiki 上对 namespace 的定义：
Namespaces are a feature of the Linux kernel that partitions kernel resources such that one set of processes sees one set of resources while another set of processes sees a different set of resources. The feature works by having the same namespace for a set of resources and processes, but those namespaces refer to distinct resources.
namespace 是 Linux 内核的一项特性，它可以对内核资源进行分区，使得一组进程可以看到一组资源；而另一组进程可以看到另一组不同的资源。该功能的原理是为一组资源和进程使用相同的 namespace，但是这些 namespace 实际上引用的是不同的资源。
这样的说法未免太绕了些，简单来说 name…]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[K8S 生态周报| Kubernetes v1.23.0 正式发布，新特性一览]]></title>
        <id>https://moelove.info/2021/12/08/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kubernetes-v1.23.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83%E6%96%B0%E7%89%B9%E6%80%A7%E4%B8%80%E8%A7%88/</id>
        <link href="https://moelove.info/2021/12/08/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kubernetes-v1.23.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83%E6%96%B0%E7%89%B9%E6%80%A7%E4%B8%80%E8%A7%88/"/>
        <updated>2021-12-07T19:50:29.000Z</updated>
        <summary type="html"><![CDATA[「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.23 即将发布，这是 2021 年发布的第三个版本，也是今年最后一个正式发布的版本。
此版本中主要包括 47 项增强更新，其中 11 项达到 stable, 17 项达到 beta 还有 19 项达到 alpha 。 当然，也有 1 项被标记为废弃。相比于 v1.22 从数量上来说是少了一点（v1.22 有 53 项增强更新），但这并不影响这是一个很棒的版本！
在 Kubernetes 的发布周期变更为 每4个月一个版本 后，很明显的感觉就是不用在升级上面花费太多时间了，毕竟 Kubernetes 的升级操作是个体力活，大家觉得呢？
我们一起来看看这个版本中有哪些值得关注的变更吧！
新增 kubectl alpha events 命令
在之前的 《K8S 生态周报| Helm 新版本发布增强对 OCI 的支持》 文章的上游进展中我曾为大家介绍了该功能。它是按照 KEP #1440 实施的。
增加此命令主要是由于在不修改 kubectl get 的前提下，查看 event 有一些限制，所以直接增加 kubectl events 命令可以更方便的去获取到需要的信息，尤其是 event 是在 Kubernetes 中经常需要查看的一个信息。kubectl get events 比较典型的一些问题, 比如排序（虽然可以通过加参数解决）， watch，以及无法按照时间线方式去查看 events 等。
我们来看看这个命令具体如何使用。
我们先来创建两个 Pod，分别叫 redis 和 redis2 。
(MoeLove) ➜ kubectl run redis --image="ghcr.io/tao12345666333/redis:a…]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Policy Agent (OPA) 入门实践]]></title>
        <id>https://moelove.info/2021/12/06/Open-Policy-Agent-OPA-%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</id>
        <link href="https://moelove.info/2021/12/06/Open-Policy-Agent-OPA-%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
        <updated>2021-12-06T11:50:29.000Z</updated>
        <summary type="html"><![CDATA[大家好，我是张晋涛。
本篇我来为你介绍一个我个人很喜欢的，通用策略引擎，名叫 OPA，全称是 Open Policy Agent。
在具体聊 OPA 之前，我们先来聊一下为什么需要一个通用策略引擎，以及 OPA 解决了什么问题。
OPA 解决了什么问题
在实际的生产环境中很多场景中都需要策略控制，比如：
需要策略控制用户是否可登陆服务器或者做一些操作；
需要策略控制哪些项目/哪些组件可进行部署；
需要策略控制如何访问数据库；
需要策略控制哪些资源可部署到 Kubernetes 中；

但是对于这些场景或者软件来说，配置它们的策略是需要与该软件进行耦合的，彼此是不统一，不通用的。管理起来也会比较混乱，带来了不小的维护成本。
OPA 的出现可以将各处配置的策略进行统一，极大的降低了维护成本。以及将策略与对应的软件/服务进行解耦，方便进行移植/复用。

OPA 的发展过程
OPA 最初是由 Styra 公司在 2016 年创建并开源的项目，目前该公司的主要产品就是提供可视化策略控制及策略执行的可视化 Dashboard 服务的。
OPA 首次进入 CNCF 并成为 sandbox 级别的项目是在 2018 年， 在 2021 年的 2 月份便已经从 CNCF 毕业，这个过程相对来说还是比较快的，由此也可以看出 OPA 是一个比较活跃且应用广泛的项目。
OPA 是什么
前面我们已经介绍过 Open Policy Agent (OPA) 是一种开源的通用策略引擎，可在整个堆栈中实现统一、上下文感知的策略控制。
OPA 可将策略决策与应用程序的业务逻辑分离（解耦），透过现象看本质，策略就是一组规则，请求发送到引擎，引擎根据规则来进行决策。

图 3 ，OPA 的策略解耦示例
OPA 并不负责具体任务的执行，它仅负责决策，需要决策的请求通过 JSON 的方式传递给 OPA ，在 OPA …]]></summary>
        <author>
            <name>zhangjintao9020@gmail.com (张晋涛)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deserve]]></title>
        <id>https://yeshan333.github.io/2021/12/04/deserve/</id>
        <link href="https://yeshan333.github.io/2021/12/04/deserve/"/>
        <updated>2021-12-04T06:49:35.000Z</updated>
        <summary type="html"><![CDATA[今天凌晨五点就醒了，积累了好多好多的情绪啊！]]></summary>
        <author>
            <name>ShanSan</name>
        </author>
    </entry>
</feed>